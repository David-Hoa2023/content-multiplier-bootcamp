# ðŸ¤– AI Integration Guide

## Tá»•ng quan

á»¨ng dá»¥ng há»— trá»£ tÃ­ch há»£p vá»›i 4 AI providers:
- **OpenAI** (GPT-4, GPT-3.5)
- **Google Gemini** (Gemini 1.5 Pro/Flash)
- **Anthropic Claude** (Claude 3.5 Sonnet, Opus, Haiku)
- **Deepseek** (Deepseek Chat/Coder)

## Cáº¥u hÃ¬nh API Keys

### BÆ°á»›c 1: Láº¥y API Keys

1. **OpenAI**: https://platform.openai.com/api-keys
2. **Gemini**: https://makersuite.google.com/app/apikey
3. **Anthropic**: https://console.anthropic.com/
4. **Deepseek**: https://platform.deepseek.com/

### BÆ°á»›c 2: ThÃªm vÃ o `.env`

Má»Ÿ file `backend/.env` vÃ  thÃªm API keys:

```env
# AI API Keys
OPENAI_API_KEY=sk-...
GEMINI_API_KEY=AIza...
ANTHROPIC_API_KEY=sk-ant-...
DEEPSEEK_API_KEY=sk-...
```

**LÆ°u Ã½:** Báº¡n chá»‰ cáº§n thÃªm API key cá»§a provider nÃ o báº¡n muá»‘n sá»­ dá»¥ng.

### BÆ°á»›c 3: Restart Backend

```bash
# Backend sáº½ tá»± Ä‘á»™ng phÃ¡t hiá»‡n providers cÃ³ sáºµn
# Xem log Ä‘á»ƒ kiá»ƒm tra: "ðŸ¤– AI Providers available: ..."
```

## API Endpoints

### 1. Láº¥y danh sÃ¡ch providers cÃ³ sáºµn

```bash
GET /ai/providers
```

Response:
```json
{
  "success": true,
  "data": ["openai", "gemini", "anthropic"],
  "message": "3 provider(s) available"
}
```

### 2. Láº¥y danh sÃ¡ch models cá»§a provider

```bash
GET /ai/providers/:provider/models
```

Example:
```bash
curl http://localhost:4000/ai/providers/openai/models
```

Response:
```json
{
  "success": true,
  "data": ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "gpt-3.5-turbo"],
  "provider": "openai"
}
```

### 3. Generate content vá»›i AI

```bash
POST /ai/generate
```

Request body:
```json
{
  "prompt": "Write a blog post about AI",
  "provider": "openai",
  "model": "gpt-4o-mini",
  "temperature": 0.7,
  "maxTokens": 2000
}
```

Parameters:
- `prompt` (required): YÃªu cáº§u cho AI
- `provider` (required): `openai` | `gemini` | `anthropic` | `deepseek`
- `model` (optional): TÃªn model cá»¥ thá»ƒ. Máº·c Ä‘á»‹nh sá»­ dá»¥ng model tá»‘t nháº¥t cá»§a provider
- `temperature` (optional): 0-2. Máº·c Ä‘á»‹nh 0.7. CÃ ng cao cÃ ng sÃ¡ng táº¡o
- `maxTokens` (optional): Sá»‘ tokens tá»‘i Ä‘a. Máº·c Ä‘á»‹nh 2000

Response:
```json
{
  "success": true,
  "data": {
    "content": "AI has revolutionized...",
    "provider": "openai",
    "model": "gpt-4o-mini",
    "tokensUsed": 150,
    "duration": "1234ms"
  }
}
```

### 4. Generate idea content (Convenience endpoint)

```bash
POST /ai/generate-idea
```

Request body:
```json
{
  "title": "Social Media Campaign",
  "persona": "Marketing Manager",
  "industry": "Technology",
  "provider": "gemini",
  "temperature": 0.8
}
```

Response:
```json
{
  "success": true,
  "data": {
    "description": "A comprehensive social media campaign...",
    "provider": "gemini",
    "model": "gemini-1.5-flash"
  }
}
```

## Retry Logic

Táº¥t cáº£ AI calls Ä‘á»u cÃ³ **automatic retry** vá»›i exponential backoff:
- Retry tá»‘i Ä‘a: **3 láº§n**
- Base delay: 1000ms (tÄƒng gáº¥p Ä‘Ã´i má»—i láº§n retry: 1s, 2s, 4s)
- KhÃ´ng retry vá»›i lá»—i authentication (401)

## VÃ­ dá»¥ sá»­ dá»¥ng

### VÃ­ dá»¥ 1: Generate vá»›i OpenAI

```bash
curl -X POST http://localhost:4000/ai/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Viáº¿t 3 Ã½ tÆ°á»Ÿng ná»™i dung vá» AI trong marketing",
    "provider": "openai",
    "model": "gpt-4o-mini",
    "temperature": 0.9
  }'
```

### VÃ­ dá»¥ 2: Generate idea vá»›i Gemini

```bash
curl -X POST http://localhost:4000/ai/generate-idea \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Video Tutorial vá» TypeScript",
    "persona": "Láº­p trÃ¬nh viÃªn má»›i",
    "industry": "Technology",
    "provider": "gemini"
  }'
```

### VÃ­ dá»¥ 3: Generate vá»›i Claude

```bash
curl -X POST http://localhost:4000/ai/generate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "PhÃ¢n tÃ­ch xu hÆ°á»›ng AI 2024",
    "provider": "anthropic",
    "model": "claude-3-5-sonnet-20241022",
    "temperature": 0.5,
    "maxTokens": 1500
  }'
```

## Default Models

Má»—i provider cÃ³ default model Ä‘Æ°á»£c chá»n tá»± Ä‘á»™ng:

| Provider | Default Model |
|----------|---------------|
| OpenAI | gpt-4o-mini |
| Gemini | gemini-1.5-flash |
| Anthropic | claude-3-5-sonnet-20241022 |
| Deepseek | deepseek-chat |

## Error Handling

CÃ¡c lá»—i phá»• biáº¿n:

1. **Provider not configured**
```json
{
  "success": false,
  "error": "OpenAI API key not configured"
}
```
â†’ ThÃªm API key vÃ o `.env`

2. **Invalid temperature**
```json
{
  "success": false,
  "error": "Temperature must be between 0 and 2"
}
```

3. **API Error** (sau 3 retries)
```json
{
  "success": false,
  "error": "Rate limit exceeded"
}
```

## Code Structure

```
backend/src/
â”œâ”€â”€ services/
â”‚   â””â”€â”€ aiService.ts       # Core AI logic vá»›i retry
â”œâ”€â”€ routes/
â”‚   â””â”€â”€ ai.ts              # API endpoints
â””â”€â”€ index.ts               # Register routes
```

## Pricing Tips

- **Development**: DÃ¹ng `gpt-4o-mini`, `gemini-1.5-flash` (ráº», nhanh)
- **Production**: DÃ¹ng `gpt-4o`, `claude-3-5-sonnet` (cháº¥t lÆ°á»£ng cao)
- Set `maxTokens` tháº¥p Ä‘á»ƒ tiáº¿t kiá»‡m chi phÃ­
- Use lower `temperature` (0.3-0.5) cho ná»™i dung factual

## Best Practices

1. **Always check available providers first**
```javascript
const providers = await fetch('/ai/providers').then(r => r.json());
```

2. **Handle errors gracefully**
```javascript
const result = await generateAI({ ... });
if (!result.success) {
  console.error(result.error);
  // Fallback logic
}
```

3. **Use appropriate temperature**
- Creative content: 0.7-1.0
- Factual content: 0.3-0.5
- Code generation: 0.2-0.4

4. **Optimize prompts**
- RÃµ rÃ ng, cá»¥ thá»ƒ
- Cho vÃ­ dá»¥ náº¿u cáº§n
- Giá»›i háº¡n Ä‘á»™ dÃ i output

---

ðŸŽ‰ Happy AI Generation!
